{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hyperparameter Tuning using Grid and Random Search.ipynb","provenance":[],"authorship_tag":"ABX9TyO1MTgbSGRPmCVhLtqGXnP2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rop-0RVHScaT"},"source":["Automated Hyperparameter Tuning: use methods such as gradient descent, Bayesian Optimization, or evolutionary algorithms to conduct a guided search for the best hyperparameters."]},{"cell_type":"markdown","metadata":{"id":"RRNdoaniVEC9"},"source":["The GBM is extremely effective on structured data - where the information is in rows and columns - and medium sized datasets - where there are at most a few million observations.\r\n","\r\n","Tthe performance is highly dependent on the hyperparameter choices. \r\n"," \r\n","GBM is an ensemble method that works by training many individual learners, almost always decision trees. \r\n","\r\n","However, unlike in a random forest where the trees are trained in parallel, in a GBM, the trees are trained sequentially with each tree learning from the mistakes of the previous ones."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuUcITlsSRMp","executionInfo":{"status":"ok","timestamp":1615058401257,"user_tz":300,"elapsed":486,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"4e1d37a2-f4cc-4e9d-9dae-0968b8602502"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/home\\ credit\\ default\\ risk"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/home credit default risk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JU-PQQSHSldR","executionInfo":{"status":"ok","timestamp":1615058401259,"user_tz":300,"elapsed":477,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}}},"source":["# Data manipulation\r\n","import pandas as pd\r\n","import numpy as np\r\n","\r\n","# Modeling\r\n","import lightgbm as lgb\r\n","\r\n","# Splitting data\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","N_FOLDS = 5\r\n","MAX_EVALS = 5"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vsvL5OiaPbl","executionInfo":{"status":"ok","timestamp":1615058410901,"user_tz":300,"elapsed":5103,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}}},"source":["features = pd.read_csv('application_train.csv')\r\n","\r\n","# Sample 16000 rows (10000 for training, 6000 for testing)\r\n","features = features.sample(n = 16000, random_state = 42)\r\n","\r\n","# Only numeric features for speeding up the hyperparameter search\r\n","features = features.select_dtypes('number')\r\n","\r\n","# Extract the labels\r\n","labels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\r\n","features = features.drop(columns = ['TARGET', 'SK_ID_CURR'])\r\n","\r\n","# Split into training and testing data\r\n","train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 6000, random_state = 50)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gp5wlWUOdqYb"},"source":["5-fold cross validation => training and testing the model with each set of hyperparameter values 5 times to assess performance.\r\n","\r\n","It is time-consuming but is a safer method to avoid overfitting"]},{"cell_type":"code","metadata":{"id":"VbEBg4dybGTO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CF9t-fpdeg7U"},"source":["###Important hyperparameters:\r\n","number of estimators (num of decision trees trained sequentially)\r\n","\r\n","method: early stopping => training until the validation error does not decrease for a specified number of iterations(?)\r\n","\r\n","Commonly applied to the GBM and to deep neural networks so it's a great technique to understand. This is one of many forms of regularization that aims to improve generalization performance on the testing set by not overfitting to the training data. "]},{"cell_type":"code","metadata":{"id":"-0blna2Xjdxv","executionInfo":{"status":"ok","timestamp":1615051220974,"user_tz":300,"elapsed":576,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}}},"source":["# Create a training and testing dataset\r\n","train_set = lgb.Dataset(data = train_features, label = train_labels)\r\n","test_set = lgb.Dataset(data = test_features, label = test_labels)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY-Z4YUPjeV1","executionInfo":{"status":"ok","timestamp":1615053338363,"user_tz":300,"elapsed":8820,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"db50d3bd-3176-46af-e8f1-7e6621a3f5cc"},"source":["# Get default hyperparameters\r\n","model = lgb.LGBMClassifier()\r\n","default_params = model.get_params()\r\n","\r\n","# Remove the number of estimators because we set this to 10000 in the cv call\r\n","del default_params['n_estimators']\r\n","\r\n","# Cross validation with early stopping\r\n","cv_results = lgb.cv(default_params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, \r\n","                    metrics = 'auc', nfold = N_FOLDS, seed = 42)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:741: UserWarning: silent keyword has been found in `params` and will be ignored.\n","Please use silent argument of the Dataset constructor to pass this parameter.\n","  .format(key))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOT4WazhrhQu","executionInfo":{"status":"ok","timestamp":1615053556767,"user_tz":300,"elapsed":511,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"1562e4db-289e-4880-95fc-8ffaf89fe4cb"},"source":["model.get_params()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'boosting_type': 'gbdt',\n"," 'class_weight': None,\n"," 'colsample_bytree': 1.0,\n"," 'importance_type': 'split',\n"," 'learning_rate': 0.1,\n"," 'max_depth': -1,\n"," 'min_child_samples': 20,\n"," 'min_child_weight': 0.001,\n"," 'min_split_gain': 0.0,\n"," 'n_estimators': 100,\n"," 'n_jobs': -1,\n"," 'num_leaves': 31,\n"," 'objective': None,\n"," 'random_state': None,\n"," 'reg_alpha': 0.0,\n"," 'reg_lambda': 0.0,\n"," 'silent': True,\n"," 'subsample': 1.0,\n"," 'subsample_for_bin': 200000,\n"," 'subsample_freq': 0}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHcOdBQXsLxL","executionInfo":{"status":"ok","timestamp":1615053608811,"user_tz":300,"elapsed":235,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"286eb22c-8e3f-4c29-bff5-d9655f5f3a9b"},"source":["print('The maximum validation ROC AUC was: {:.5f} with a standard deviation of {:.5f}.'.format(cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\r\n","print('The optimal number of boosting rounds (estimators) was {}.'.format(len(cv_results['auc-mean'])))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["The maximum validation ROC AUC was: 0.70058 with a standard deviation of 0.02819.\n","The optimal number of boosting rounds (estimators) was 23.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bh-4ydVVslZI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wqcqiTN602-m"},"source":["Four parts of Hyperparameter tuning\r\n","It's helpful to think of hyperparameter tuning as having four parts (basis of Bayesian Optimization):\r\n","\r\n","* Objective function: a function that takes in hyperparameters and returns a score we are trying to minimize or maximize\r\n","* Domain: the set of hyperparameter values over which we want to search.\r\n","* Algorithm: method for selecting the next set of hyperparameters to evaluate in the objective function.\r\n","* Results history: data structure containing each set of hyperparameters and the resulting score from the objective function.\r\n","\r\n","Switching from grid to random search to Bayesian optimization will only require making minor modifications to these four parts."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w48Kvlvo1iS3","executionInfo":{"status":"ok","timestamp":1615058400752,"user_tz":300,"elapsed":8472,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"ccc2a621-d6e6-4ff8-f000-90bc605efaa0"},"source":["def objective(hyperparameters, iteration):\r\n","    \"\"\"Objective function for grid and random search. Returns\r\n","       the cross validation score from a set of hyperparameters.\"\"\"\r\n","    \r\n","    # Number of estimators will be found using early stopping\r\n","    if 'n_estimators' in hyperparameters.keys():\r\n","        del hyperparameters['n_estimators']\r\n","    \r\n","     # Perform n_folds cross validation\r\n","    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \r\n","                        early_stopping_rounds = 100, metrics = 'auc', seed = 42)\r\n","    \r\n","    # results to retun\r\n","    score = cv_results['auc-mean'][-1]\r\n","    estimators = len(cv_results['auc-mean'])\r\n","    hyperparameters['n_estimators'] = estimators \r\n","    \r\n","    return [score, hyperparameters, iteration]\r\n","  \r\n","score, params, iteration = objective(default_params, 1)\r\n","\r\n","print('The cross-validation ROC AUC was {:.5f}.'.format(score))\r\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["The cross-validation ROC AUC was 0.70058.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uGXrR71l-1RB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6_zYe4xc_Bsf"},"source":["http://lightgbm.readthedocs.io/en/latest/Parameters.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVFJSrie_CPe","executionInfo":{"status":"ok","timestamp":1615058458473,"user_tz":300,"elapsed":238,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"178e28a5-3b67-44ca-87f9-cf5c29a2e293"},"source":["# Create a default model\r\n","model = lgb.LGBMModel()\r\n","model.get_params()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'boosting_type': 'gbdt',\n"," 'class_weight': None,\n"," 'colsample_bytree': 1.0,\n"," 'importance_type': 'split',\n"," 'learning_rate': 0.1,\n"," 'max_depth': -1,\n"," 'min_child_samples': 20,\n"," 'min_child_weight': 0.001,\n"," 'min_split_gain': 0.0,\n"," 'n_estimators': 100,\n"," 'n_jobs': -1,\n"," 'num_leaves': 31,\n"," 'objective': None,\n"," 'random_state': None,\n"," 'reg_alpha': 0.0,\n"," 'reg_lambda': 0.0,\n"," 'silent': True,\n"," 'subsample': 1.0,\n"," 'subsample_for_bin': 200000,\n"," 'subsample_freq': 0}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"3CUtAlEc_Qm_"},"source":["the number of individual learners trained, n_estimators (also referred to as num_boost_rounds or the number of iterations)\r\n","\r\n","If we have prior experience with a model, we might know where the best values for the hyperparameters typically lie, or what a good search space is. However, if we don't have much experience, we can simply define a large search space and hope that the best values are in there somewhere. Typically, when first using a method, I define a wide search space centered around the default values. Then, if I see that some values of hyperparameters tend to work better, I can concentrate the search around those values"]},{"cell_type":"code","metadata":{"id":"XIntAhI6_FY9","executionInfo":{"status":"ok","timestamp":1615060195526,"user_tz":300,"elapsed":173,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}}},"source":["# Hyperparameter grid\r\n","param_grid = {\r\n","    'boosting_type': ['gbdt', 'goss', 'dart'],\r\n","    'num_leaves': list(range(20, 150)),\r\n","    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 1000)),\r\n","    'subsample_for_bin': list(range(20000, 300000, 20000)),\r\n","    'min_child_samples': list(range(20, 500, 5)),\r\n","    'reg_alpha': list(np.linspace(0, 1)),\r\n","    'reg_lambda': list(np.linspace(0, 1)),\r\n","    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\r\n","    'subsample': list(np.linspace(0.5, 1, 100)),\r\n","    'is_unbalance': [True, False]\r\n","}"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOVjjnnSC-UM"},"source":["When we get to Bayesian Optimization, the model actually uses the past results to decide on the next hyperparmeters to evaluate. Random and grid search(an exhaustive methoud: try and check) are uninformed methods that do not use the past history, but we still need the history so we can find out which hyperparameters worked the best!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yn719U4C_7f","executionInfo":{"status":"ok","timestamp":1615060205928,"user_tz":300,"elapsed":163,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"659eba8f-85f0-4003-ca0a-e032a94f40c6"},"source":["# random search : more efficient way\r\n","import random\r\n","\r\n","random.seed(50)\r\n","# Randomly sample from dictionary\r\n","random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\r\n","# Deal with subsample ratio\r\n","random_params['subsample'] = 1.0 if random_params['boosting_type'] == 'goss' else random_params['subsample']\r\n","\r\n","random_params"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'boosting_type': 'goss',\n"," 'colsample_bytree': 0.8222222222222222,\n"," 'is_unbalance': False,\n"," 'learning_rate': 0.027778881111994384,\n"," 'min_child_samples': 175,\n"," 'num_leaves': 88,\n"," 'reg_alpha': 0.8979591836734693,\n"," 'reg_lambda': 0.6122448979591836,\n"," 'subsample': 1.0,\n"," 'subsample_for_bin': 220000}"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"QRXIYmtlFprK","executionInfo":{"status":"ok","timestamp":1615062305300,"user_tz":300,"elapsed":426,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}}},"source":["def random_search(param_grid, max_evals = MAX_EVALS):\r\n","    \"\"\"Random search for hyperparameter optimization\"\"\"\r\n","    \r\n","    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\r\n","                                  index = list(range(MAX_EVALS)))\r\n","    \r\n","    # Keep searching until reach max evaluations\r\n","    for i in range(MAX_EVALS):\r\n","        # Choose random hyperparameters\r\n","        hyperparameters = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\r\n","        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\r\n","\r\n","        # Evaluate randomly selected hyperparameters\r\n","        eval_results = objective(hyperparameters, i)\r\n","        \r\n","        results.loc[i, :] = eval_results\r\n","    \r\n","    # Sort with best score on top\r\n","    results.sort_values('score', ascending = False, inplace = True)\r\n","    results.reset_index(inplace = True)\r\n","    return results "],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jfOFSQGGL8-","executionInfo":{"status":"ok","timestamp":1615063886264,"user_tz":300,"elapsed":1580708,"user":{"displayName":"Yingfei Fan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRyJ1s6xnLiGcZ3co5Lvu_uw8s9ibOmBilvLyz=s64","userId":"06222129021084483374"}},"outputId":"c9b5d21e-877b-430a-81df-4f7c50ba4798"},"source":["# oh gosh, it takes foever to run this cell \r\n","import time\r\n","start_time = time.time()\r\n","\r\n","random_results = random_search(param_grid)\r\n","\r\n","print('The best validation score was {:.5f}'.format(random_results.loc[0, 'score']))\r\n","print('\\nThe best hyperparameters were:')\r\n","\r\n","import pprint\r\n","pprint.pprint(random_results.loc[0, 'params'])\r\n","\r\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/lightgbm/callback.py:189: UserWarning: Early stopping is not available in dart mode\n","  warnings.warn('Early stopping is not available in dart mode')\n"],"name":"stderr"},{"output_type":"stream","text":["The best validation score was 0.72667\n","\n","The best hyperparameters were:\n","{'boosting_type': 'gbdt',\n"," 'colsample_bytree': 0.6888888888888889,\n"," 'is_unbalance': True,\n"," 'learning_rate': 0.04655206743534537,\n"," 'min_child_samples': 435,\n"," 'n_estimators': 74,\n"," 'num_leaves': 125,\n"," 'reg_alpha': 0.6938775510204082,\n"," 'reg_lambda': 0.2857142857142857,\n"," 'subsample': 0.9646464646464648,\n"," 'subsample_for_bin': 260000}\n","--- 1580.4456079006195 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vhjv1dWPGPyA"},"source":[""],"execution_count":null,"outputs":[]}]}